{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Uses of Generative AI \n",
    "\n",
    "## AI Math Tutor ‚Äì Fine-Tuned ChatGPT for Elementary Learners\n",
    "\n",
    "This project explores the use of fine-tuning techniques to create an interactive AI-powered math tutor designed for elementary students. Using the OpenAI API, a base ChatGPT Turbo model was fine-tuned to deliver clear, friendly, and age-appropriate explanations‚Äîeven when students provide vague or unstructured input.\n",
    "\n",
    "The project follows the official OpenAI fine-tuning workflow and incorporates strategies from *Generative AI in Action* (Chapter 7), including prompt design, data formatting, and conversational behavior shaping.\n",
    "\n",
    "This notebook documents the complete end-to-end process:\n",
    "- Preparing and formatting training data in JSONL\n",
    "- Uploading and managing files with the OpenAI CLI\n",
    "- Running the fine-tuning job\n",
    "- Testing and evaluating the customized model responses\n",
    "\n",
    "The final model is integrated into a Streamlit web application to deliver a simple and engaging interface for student use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the steps I followed to fine-tune a generative AI model using the OpenAI API and Python:\n",
    "\n",
    "- **Dataset Creation:**\n",
    "  \n",
    "    I created a small, high-quality dataset of kid-friendly math question-answer pairs using OpenAI's chat fine-tuning format, ensuring a friendly          tone, emojis, and second-grade-level analogies.  The dataset was validated to ensure correct formatting and readiness for fine-tuning.\n",
    "\n",
    "- **Uploading the Dataset:**\n",
    "  \n",
    "    The training file was uploaded to OpenAI using the REST API.\n",
    "\n",
    "- **Fine-Tuning the Model:**\n",
    "  \n",
    "    A fine-tuning job was launched using gpt-3.5-turbo, and progress was monitored until completion.\n",
    "\n",
    "- **Testing and Evaluation:**\n",
    "  \n",
    "    After fine-tuning, I tested the model on new prompts to evaluate tone, clarity, and how well it followed the desired kid-friendly style.\n",
    "\n",
    "- **Reflections and Observations:**\n",
    "  \n",
    "    I documented insights from the results, including improvements over the base model and any limitations or next steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up OpenAI API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, I imported the necessary libraries and retrieved the API key from the system's environment variables. This ensures that the API key is securely accessed and available for making the API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# The API key is stored as an environment variable for security reasons.\n",
    "# It is set in the system environment and can be accessed by using the os.getenv() function.\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# If the key is missing, it will print an error message to indicate the issue.\n",
    "if not api_key:\n",
    "    print(\"Error: API key is not set. Please ensure the OPENAI_API_KEY environment variable is configured properly.\")\n",
    "    print(\"To set your API key, run the following command in your terminal: export OPENAI_API_KEY=your_api_key_here\")\n",
    "    exit(1)  # Exit if the API key is not found\n",
    "\n",
    "# Set the API key for the OpenAI API\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this milestone, I created a custom training dataset designed to help the model respond to elementary math questions with warm, age-appropriate explanations.\n",
    "\n",
    "The dataset was hand-crafted in JSONL format, with each record containing a user prompt (e.g., a math question) and an assistant response (e.g., a cheerful, emoji-enhanced explanation). Each entry followed the OpenAI fine-tuning schema using a messages list with clearly defined user and assistant roles.\n",
    "\n",
    "To keep the fine-tuning process manageable for this exercise, I used 10 high-quality examples and ensured that each sample was:\n",
    "\n",
    "- Engaging and easy to follow for a second-grade reading level\n",
    "\n",
    "- Aligned with best practices for fine-tuning (no special tokens, consistent formatting)\n",
    "\n",
    "- Valid JSONL with no parsing issues or escape character errors\n",
    "\n",
    "This dataset served as the foundation for the fine-tuning process that followed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I verified the first couple of records to confirm the data was correctly formatted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"user\", \"content\": \"What is 7 + 5? Explain it like I'm in 2nd grade.\"}, {\"role\": \"assistant\", \"content\": \"Let‚Äôs count on our fingers! Start with 7 fingers up, and then count 5 more: 8, 9, 10, 11, 12! So, 7 + 5 = 12! üéâ You did it! üéâ\"}]}\n",
      "\n",
      "{\"messages\": [{\"role\": \"user\", \"content\": \"I have 3 boxes of crayons. Each box has 4 crayons. How many crayons do I have in total?\"}, {\"role\": \"assistant\", \"content\": \"Let‚Äôs do the math! If each box has 4 crayons and you have 3 boxes, you multiply 3 x 4 = 12 crayons! That‚Äôs a whole rainbow of colors! üåà\"}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the original file and read the contents\n",
    "with open('math_tutor_dataset.jsonl', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Print the first two records as-is\n",
    "for record in lines[:2]:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading the Cleaned Dataset for Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset was prepared, the next step was to upload it to OpenAI‚Äôs servers to make it ready for the fine-tuning process. This involved using the OpenAI API to upload the training file. The dataset would then be used to fine-tune the base model, ensuring it can respond with age-appropriate, engaging math explanations.\n",
    "\n",
    "To handle potential issues during the upload, I implemented error handling in the code to ensure smooth file submission. This step made the dataset available for fine-tuning, allowing the model to learn from the provided examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file uploaded successfully. File ID: file-WUD3eoUxN4Y7JpsxCeXjpd\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "TRAINING_FILENAME = 'math_tutor_dataset.jsonl'  # Path to the cleaned training dataset\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Upload the training file to OpenAI's servers\n",
    "try:\n",
    "    # Open the training file in binary mode ('rb') for reading\n",
    "    with open(TRAINING_FILENAME, \"rb\") as f:\n",
    "        # Upload the file to OpenAI with the purpose of fine-tuning\n",
    "        file_response = client.files.create(\n",
    "            file=f,  # The file to upload\n",
    "            purpose=\"fine-tune\"  # The purpose for the file upload (fine-tuning)\n",
    "        )\n",
    "    \n",
    "    # Extract the file ID from the response\n",
    "    training_file_id = file_response.id\n",
    "    \n",
    "    # Print a success message with the file ID\n",
    "    print(f\"Training file uploaded successfully. File ID: {training_file_id}\")\n",
    "\n",
    "# Handle any exceptions that occur during the file upload process\n",
    "except Exception as e:\n",
    "    # Print the error message and exit the program if file upload fails\n",
    "    print(f\"Error uploading training file: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading the cleaned training dataset, the next step was to initiate the fine-tuning job using the file ID provided by OpenAI. This triggered the model training process, enabling the model to learn from the dataset and improve its ability to provide age-appropriate math explanations.\n",
    "\n",
    "For this fine-tuning task, I selected the base model (gpt-3.5-turbo) and set the relevant hyperparameters, such as the number of training epochs (n_epochs), to control how many times the model would learn from the dataset. Additionally, I applied a custom suffix to the fine-tuned model‚Äôs name for easy identification.\n",
    "\n",
    "Once the job was successfully created, I received a job ID, which I used to monitor the progress and status of the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job started successfully. Job ID: ftjob-HS8NjJ9TFAKnDJxoVSSx8lSp\n"
     ]
    }
   ],
   "source": [
    "# Initiate fine-tuning job\n",
    "try:\n",
    "    # Create the fine-tuning job using the uploaded training file and model parameters\n",
    "    fine_tune_response = client.fine_tuning.jobs.create(\n",
    "        training_file=training_file_id,  # Pass the uploaded training file ID\n",
    "        model=\"gpt-3.5-turbo\",  # Specify the base model for fine-tuning (gpt-3.5-turbo)\n",
    "        hyperparameters={\"n_epochs\": 3},  # Set hyperparameters for fine-tuning (e.g., number of epochs)\n",
    "        suffix=\"math_tutor\"  # Add a custom suffix to the fine-tuned model for identification\n",
    "    )\n",
    "    \n",
    "    # Extract the job ID from the response\n",
    "    fine_tuning_job_id = fine_tune_response.id\n",
    "    \n",
    "    # Print success message with the job ID for monitoring purposes\n",
    "    print(f\"Fine-tuning job started successfully. Job ID: {fine_tuning_job_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # If there is an error in initiating the fine-tuning job, print the error message and exit\n",
    "    print(f\"Error initiating fine-tuning job: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring and Documenting the Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initiating the fine-tuning job, I used the OpenAI API to monitor its status and document the training progress. This involved two key parts:\n",
    "\n",
    "- **Job Monitoring**\n",
    "  \n",
    "    I implemented a script to track the job status by querying the OpenAI endpoint every 30 seconds. The script continued polling until the job either      succeeded or failed. Upon successful completion, I retrieved the fine-tuned model name for future inference tasks.\n",
    "\n",
    "- **Metrics Tracking**\n",
    "  \n",
    "    Once the job completed, I retrieved detailed job events including training loss logged at each step. These events provided visibility into how the      model learned over time. The final output included the job status and the ID of the fine-tuned model.\n",
    "\n",
    "Here's the code I used to monitor the fine-tuning job and retrieve the status amd metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fine_tuning_job_status(job_id):\n",
    "    # Function to retrieve the status of a fine-tuning job\n",
    "    url = f\"https://api.openai.com/v1/fine_tuning/jobs/{job_id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"  # Use environment variable for API key\n",
    "    }\n",
    "    try:\n",
    "        # Send GET request to retrieve job status\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        job_data = response.json()\n",
    "        return job_data['status']  # Return job status (succeeded, failed, etc.)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle request exceptions (e.g., network errors)\n",
    "        print(f\"Error retrieving fine-tuning job status: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle errors when decoding the JSON response\n",
    "        print(\"Error decoding JSON response.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring fine-tuning job...\n",
      "Fine-tuning job completed with status: succeeded\n",
      "Fine-tuned model name: ft:gpt-3.5-turbo-0125:personal:math-tutor:BVPvM7jo\n",
      "\n",
      "--- Training Metrics ---\n",
      "1746827527: The job has successfully completed\n",
      "1746827521: New fine-tuned model created\n",
      "1746827520: Checkpoint created at step 30\n",
      "1746827520: Checkpoint created at step 15\n",
      "1746827508: Step 45/45: training loss=0.49\n",
      "1746827508: Step 44/45: training loss=0.58\n",
      "1746827505: Step 43/45: training loss=0.58\n",
      "1746827505: Step 42/45: training loss=0.44\n",
      "1746827505: Step 41/45: training loss=0.43\n",
      "1746827502: Step 40/45: training loss=0.40\n",
      "1746827502: Step 39/45: training loss=0.68\n",
      "1746827499: Step 38/45: training loss=0.25\n",
      "1746827496: Step 37/45: training loss=0.27\n",
      "1746827496: Step 36/45: training loss=0.57\n",
      "1746827494: Step 35/45: training loss=0.65\n",
      "1746827494: Step 34/45: training loss=0.41\n",
      "1746827494: Step 33/45: training loss=0.66\n",
      "1746827491: Step 32/45: training loss=0.42\n",
      "1746827491: Step 31/45: training loss=0.54\n",
      "1746827485: Step 30/45: training loss=0.55\n",
      "\n",
      "Final Status: succeeded\n",
      "Fine-tuned model: ft:gpt-3.5-turbo-0125:personal:math-tutor:BVPvM7jo\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Monitor the fine-tuning job status\n",
    "if fine_tuning_job_id:\n",
    "    print(\"Monitoring fine-tuning job...\")\n",
    "    while True:\n",
    "        # Check job status\n",
    "        status = get_fine_tuning_job_status(fine_tuning_job_id)\n",
    "        \n",
    "        # If job is completed (either succeeded or failed), break the loop\n",
    "        if status in [\"succeeded\", \"failed\"]:\n",
    "            break\n",
    "        \n",
    "        # Print status and wait before checking again\n",
    "        print(f\"Status: {status}. Checking again in 30 seconds...\")\n",
    "        time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "\n",
    "    print(f\"Fine-tuning job completed with status: {status}\")\n",
    "\n",
    "    if status == \"succeeded\":\n",
    "        # If job succeeded, retrieve the fine-tuned model ID\n",
    "        url = f\"https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        job_data = response.json()\n",
    "        fine_tuned_model_name = job_data['fine_tuned_model']\n",
    "        print(f\"Fine-tuned model name: {fine_tuned_model_name}\")\n",
    "\n",
    "        # Retrieve and print training metrics from OpenAI client\n",
    "        client = OpenAI()\n",
    "        events = client.fine_tuning.jobs.list_events(fine_tuning_job_id)\n",
    "\n",
    "        print(\"\\n--- Training Metrics ---\")\n",
    "        for event in events.data:\n",
    "            print(f\"{event.created_at}: {event.message}\")\n",
    "\n",
    "        job_info = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "        print(f\"\\nFinal Status: {job_info.status}\")\n",
    "        print(f\"Fine-tuned model: {job_info.fine_tuned_model}\")\n",
    "\n",
    "    else:\n",
    "      print(\"Fine-tuning failed.\")\n",
    "      fine_tuned_model_name = None\n",
    "else:\n",
    "    # Handle case where fine-tuning job ID is not available\n",
    "    print(\"Fine-tuning job ID is not available. Cannot monitor.\")\n",
    "    fine_tuned_model_name = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loss helps assess how well the model is fitting the data.  \n",
    "\n",
    "The training process concluded with a final loss of 0.49 over 45 steps, indicating that the model effectively learned from the limited dataset. While this loss value suggests a good fit for the training data, it's important to note that a more extensive and diverse dataset would be necessary to ensure the model's robustness and generalization capabilities in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the fine-tuning job successfully completed and the fine-tuned model ready, I proceeded to test both the base model (gpt-3.5-turbo) and the newly fine-tuned model using a set of sample prompts. The goal of this step was to compare the responses from the base model and the fine-tuned model to see how they differed in terms of relevance, engagement, and clarity, particularly for elementary math questions.\n",
    "\n",
    "This quick comparison helped me evaluate whether the fine-tuned model performed as expected and provided age-appropriate, engaging, and helpful explanations for the target audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, test_strings, description):\n",
    "    print(f\"\\nTesting {description}: {model_name}\")\n",
    "    for test_string in test_strings:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a friendly and engaging math tutor who provides clear, fun, and easy-to-understand math explanations for elementary students. Use emojis and simple language to explain the concepts.\"},\n",
    "                    {\"role\": \"user\", \"content\": test_string}\n",
    "                ],\n",
    "                max_tokens=75,\n",
    "            )\n",
    "            output = response.choices[0].message.content.strip()\n",
    "            print(f\"\\nInput: {test_string}\")\n",
    "            print(f\"Output: {output}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error testing model with input '{test_string}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test foundation model ---\n",
      "\n",
      "Testing foundation model: gpt-3.5-turbo\n",
      "\n",
      "Input: What is 5 + 3?\n",
      "Output: Great question! üåü When you add 5 and 3 together, you get 8! üéâ So, 5 + 3 = 8. Isn't math fun? üòÄüßÆ\n",
      "\n",
      "\n",
      "Input: Can you explain what 10 divided by 2 means?\n",
      "Output: Of course! üåü When we divide 10 by 2, it means we are sharing 10 things equally into 2 groups. ü§ù So, if we have 10 cookies and we want to share them with 2 friends, each friend would get 5 cookies. üç™üç™üç™üç™üç™ So\n",
      "\n",
      "\n",
      "Input: I have 16 cookies üç™ and want to share them equally with 4 friends. How many cookies will each friend get?\n",
      "Output: Great question! üåü If you have 16 cookies üç™ and want to share them equally with 4 friends, you can divide the total number of cookies by the number of friends. \n",
      "16 cookies √∑ 4 friends = 4 cookies each! üéâ\n",
      "Each friend will get 4 cookies. Enjoy sharing your yummy cookies! üòä\n",
      "\n",
      "\n",
      "--- Test fine-tuned model ---\n",
      "\n",
      "Testing fine-tuned model: ft:gpt-3.5-turbo-0125:personal:math-tutor:BVPvM7jo\n",
      "\n",
      "Input: What is 5 + 3?\n",
      "Output: Great question! üéâ Let‚Äôs think of numbers as toys at a playdate! üß∏ So if we have 5 toys üß∏ and 3 more friends come over, how many toys do we have all together? üåü Let‚Äôs count them all! 1, 2, 3, 4, 5, 6,\n",
      "\n",
      "\n",
      "Input: Can you explain what 10 divided by 2 means?\n",
      "Output: Absolutely! Let's say the üçï has 10 slices and there are 2 of you üßíüßí. If you share equally, each of you get 5 slices. Remember 10 √∑ 2 = 5! Easy-peasy! üòâüçïüëßüëß\n",
      "\n",
      "\n",
      "Input: I have 16 cookies üç™ and want to share them equally with 4 friends. How many cookies will each friend get?\n",
      "Output: Time to do some sharing! Let‚Äôs give each friend the same number of cookies. Start by dividing the üç™ into groups. 16 cookies √∑ 4 friends = 4 cookies per friend! Now each friend can enjoy 4 yummy cookies! üéâ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Prompt strings \n",
    "test_prompts = [\n",
    "    \"What is 5 + 3?\",\n",
    "    \"Can you explain what 10 divided by 2 means?\",\n",
    "    \"I have 16 cookies üç™ and want to share them equally with 4 friends. How many cookies will each friend get?\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Test foundation model ---\")\n",
    "# Test foundation model\n",
    "test_model(\"gpt-3.5-turbo\", test_prompts, \"foundation model\")\n",
    "\n",
    "print(\"\\n--- Test fine-tuned model ---\")\n",
    "# Test fine-tuned model\n",
    "if fine_tuned_model_name:\n",
    "    test_model(fine_tuned_model_name, test_prompts, \"fine-tuned model\")\n",
    "else:\n",
    "    print(\"No fine-tuned model to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of the results and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning worked well and successful in shaping the model's responses to better suit its intended audience. The fine-tuned model consistently delivered responses in a more playful, child-friendly tone that matched the goal of building an elementary math tutor. It used metaphors (like toys and pizza), added emojis, and kept the tone encouraging and fun‚Äîall of which help make math more engaging for young students.\n",
    "\n",
    "That said, the base GPT-3.5-turbo model also performed well. It gave accurate and clear answers, and in some cases, was a bit more concise. However, it didn‚Äôt always maintain the consistent, imaginative tone or child-oriented language that the fine-tuned version achieved.\n",
    "\n",
    "Overall, both models were capable, but the fine-tuned version better matched the intended teaching style for younger audiences. This shows that fine-tuning can be a powerful tool to adapt a general-purpose model to meet specific communication needs and user groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Metrics Considered**\n",
    "\n",
    "Given the scope of our term project and the limited size of our fine-tuning dataset, I focused on the following key metrics to evaluate our model's performance:\n",
    "\n",
    "Training Loss: The final training loss achieved was 0.495, indicating that the model effectively minimized errors on the training data.\n",
    "\n",
    "Training Accuracy: The model attained a training accuracy of 80.9%, reflecting its proficiency in predicting the correct tokens during training.\n",
    "\n",
    "These metrics were obtained from the OpenAI fine-tuning dashboard, which provides real-time insights into the model's learning progress .\n",
    "\n",
    "- **Model Testing and Validation**\n",
    "\n",
    "To assess the qualitative improvements brought by fine-tuning, I conducted comparative testing between the base model (gpt-3.5-turbo) and fine-tuned model. \n",
    "\n",
    "#### Key observations include:\n",
    "\n",
    " *Enhanced Engagement:* The fine-tuned model consistently incorporated emojis and adopted a more conversational tone, aligning with our objective of creating a friendly math tutor for elementary students.\n",
    "\n",
    " *Improved Clarity:* Explanations provided by the fine-tuned model were more tailored to young learners, using simple language and relatable examples.\n",
    "\n",
    "- **Human Evaluation**\n",
    "\n",
    "Recognizing the importance of human judgment in evaluating generative models, I performed manual reviews of the model's responses. This involved:\n",
    "\n",
    "Comparative Analysis: Assessing outputs from both the base and fine-tuned models to identify improvements in tone, clarity, and engagement.\n",
    "\n",
    "Qualitative Feedback: Noting areas where the fine-tuned model excelled or required further refinement.\n",
    "\n",
    "While this evaluation was informal, it provided valuable insights into the model's real-world applicability and effectiveness in achieving our educational goals.\n",
    "\n",
    "- **Token Size Experimentation**\n",
    "\n",
    "One key learning from this project was the impact of the max_tokens parameter on the completeness of the model‚Äôs responses. Initially, setting a low max_tokens value resulted in truncated outputs, limiting the model‚Äôs ability to deliver full explanations. To address this, the parameter was gradually increased, which enabled the model to generate more comprehensive and coherent responses. This experimentation highlighted the importance of carefully tuning generation parameters to achieve a balance between response quality and resource efficiency.\n",
    "\n",
    "    \n",
    "### Conclusion\n",
    "    \n",
    "Throughout this milestone, I gained several important learnings:\n",
    "\n",
    "**Fine-Tuning Effectiveness:** Even with a modest dataset, fine-tuning can significantly enhance a model's alignment with specific stylistic and functional objectives.\n",
    "\n",
    "**Importance of Evaluation Metrics:** Monitoring training loss and accuracy provides essential feedback on the model's learning trajectory, while human evaluations offer nuanced insights into its practical performance.\n",
    "\n",
    "**Prompt and Parameter Tuning:** Adjusting prompt and generation parameters like max_tokens is crucial for optimizing output quality.\n",
    "\n",
    "For future work, expanding the dataset and incorporating more structured evaluations would further strengthen the model's capabilities and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
